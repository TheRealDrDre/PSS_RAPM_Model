---
title: "RAPM Experiments Data Analysis"
author: "Andrea Stocco"
date: "August 11, 2019"
output: 
  html_document:
    code_folding: hide
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
  word_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
library(tidyverse)
library(kableExtra)
library(xtable)
library(ggplot2)
library(Hmisc)
library(gridExtra)
knitr::opts_chunk$set(echo = TRUE)
```

# RAPM Experiments analysis

First, let's define four functions that will be used over and over in this document and for the paper figures:

```{r}
plot.correlations.size <- function(data, xvar, yvar, xlab=xvar, ylab=yvar, leg=F, legpos="bottom", corpos=c(0.2, 0.2), xlim=c(0, 1), legcols=NA, ...) {
  attach(data)
  mod <- lm(as.formula(paste(yvar, xvar, sep="~")))
  
  range <- (xlim[2] - xlim[1])
  newx <- data.frame(X=seq(xlim[1] - 1/2 *range, xlim[2] + 1/2 * range, range/1000)) 
  names(newx) <- c(xvar)  # Rename to X variable in data frame	
  newy <- predict(mod, newdata=newx, interval="confidence", level=0.95) 	
  detach(data)
  k <- data
  k$Count <- 0
  kz <- aggregate(k$Count, list(xvar=k[[xvar]], yvar=k[[yvar]]), length)
  #print(kz$x)
  plot(kz$xvar, kz$yvar, pch=21, bg="white", col="white", cex=kz$x, 
       fg="grey15", xlab="", ylab="", col.axis="grey15", col.lab="grey15", xlim=xlim, ...)
  p <- cor.test(data[[xvar]], data[[yvar]])$p.value
  significance = ""
  if (p < 0.05) {
    line <- "red"
    shade <- "#FF222222"
    significance = "*"
    if (p < 0.01) {significance = "**"}
    if (p < 0.001) {significance = "***"}
  } else {
    line <- "black"
    shade <- "#22222222"
  }
  bgs=c("#77777799", "#44444499", "#11111199", "#11111199")
  polygon(c(newx[[xvar]], rev(newx[[xvar]])), c(newy[,2], rev(newy[,3])), col=shade, border=F)
  points(kz$xvar, kz$yvar, pch=21, bg=sapply(kz$x, function(x){bgs[x]}), col="white", cex=1.5 * sqrt(kz$x), 
       fg="grey15", xlab="", ylab="", col.axis="grey15", col.lab="grey15", xlim=xlim, ...)
  #points(data[[xvar]], data[[yvar]], pch=21, bg="#11111166", col="white", cex=1.5)
  abline(mod, col=line, lwd=2, lty=3)
  
  r <- round(cor(data[[xvar]], data[[yvar]]), 2)
  #detach(data)
  text(x=corpos[1], y=corpos[2], col=line, labels=substitute(italic(r)(n) == x~s, list(n=length(data[[xvar]]), x=r, s=significance)))
  mtext(ylab, side=2, line=2, col="grey15")
  mtext(xlab, side=1, line=2, col="grey15")
  if (leg) {
    if (is.na(legcols)) {legcols <- max(kz$x)}
    legend(x=legpos, ncol=legcols, legend=paste("n=", sep="", sort(unique(kz$x))), pch=21,
           col="white", pt.bg=sapply(unique(kz$x), function(x){bgs[x]}), pt.cex= 1.5*sqrt(unique(kz$x)),
           bg="#CCCCCC88", box.col = NA)
  }
  box(bty="O")
}
```

## Experiment 1

```{r}
behav1 <- read.table("experiment1.txt", header=T, sep="\t")

# Remove all the participants for which we do not have complete data
# 
behav1 <- subset(behav1, !is.na(behav1$RAPM) 
                 & !is.na(behav1$AvoidB) 
                 & !is.na(behav1$ChooseA) 
                 & !is.na(behav1$OS_Score))
```

Because Experiments 1-3 have different number of problems, we are going to normalize the performance variable as the proportion of correct problems solved. This will make sure all the correlations are on the same scale.

```{r}
behav1$RAPM_Accuracy <- behav1$RAPM / 34
```

There are four behavioral variables of interest in this data. Avoid accuracy (`AvoidB`) and Choose accuracy (`ChooseA`) come from the PSS task; Operation Span (`OS_Score`) comes from the Operation Span task; and RAPM Accuracy (`RAPM_Accuracy`) comes from the Raven's Advanced Progressive Matrices test.  

```{r}
vars_of_interest <- c("ChooseA", "AvoidB", "OS_Score", "RAPM_Accuracy")
```

### Descriptive statistics

Given this, we can look at some basic features. First, we can look at the distribution of the four variables:

```{r}
longb <- gather(behav1, variable, measure, vars_of_interest)
ggplot(longb, aes(measure, fill=variable)) +
  geom_histogram(col=I("white"), bins = 16) +
  facet_wrap( . ~ variable, scales= "free") +
  theme_linedraw()
```


Second, let's look at their mean values:

```{r}
ggplot(longb, aes(x=variable, y=measure, fill=variable)) +
  stat_summary(fun.data="mean_se", geom = "bar", width=0.5) +
  stat_summary(fun.data="mean_se", geom = "errorbar", width=0.1) +
  facet_wrap( . ~ variable, scales= "free") +
  theme_linedraw()
```

### A comparison of Choose and Avoid accuracies

As expected, the mean values of Choose (_M_ = `r round(mean(behav1$ChooseA), 3)`, _SD_ = `r round(sd(behav1$ChooseA), 3)`) and Avoid (_M_ = `r round(mean(behav1$AvoidB), 3)`, _SD_ = `r round(sd(behav1$AvoidB), 3)`) are approximately the same. A _t_-test shows no difference between the two values:

```{r}
t <- t.test(behav1$ChooseA, behav1$AvoidB, paired = T)
```

with _t_(`r t$parameter`) = `r t$statistic`, _p_ = `r t$p.value`.

### Correlations between variables

First, we can examine the correlation matrix between these varibles:

```{r}
cor(behav1[vars_of_interest]) %>%
  kable(digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We can also calculate the correspinding _p_-values:

```{r}
behav1[vars_of_interest] %>% 
  as.matrix() %>% 
  rcorr() -> pvals

pvals$P %>%
  kable(digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

And finally, we can examine the scatterplots of the correlations between variables:

```{r fig, fig.height = 8, warning=F}
sp1 <- ggplot(behav1, aes(x = ChooseA, y = AvoidB)) +
  #stat_bin_hex(bins=16, col="white") + 
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, col="black", fullrange= T) +
  xlab("Choose Accuracy") +
  ylab("Avoid Accuracy") + 
  theme_linedraw()

sp2 <- ggplot(behav1, aes(x = RAPM_Accuracy, y = OS_Score)) +
#  stat_bin_hex(bins=16, col="white") + 
  geom_count( alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, col="red", fullrange= T) +
  xlab("RAPM Accuracy") +
  ylab("Operation Span") + 
  theme_linedraw()

sp3 <- ggplot(behav1, aes(x = ChooseA, y = RAPM_Accuracy)) +
  #stat_bin_hex(bins=16, col="white") + 
  geom_count( alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, col="black", fullrange= T) +
  theme_linedraw()

sp4 <- ggplot(behav1, aes(x = AvoidB, y = RAPM_Accuracy)) +
  #stat_bin_hex(bins=16, col="white") + 
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, col="red", fullrange= T) +
  theme_linedraw()

sp5 <- ggplot(behav1, aes(x = ChooseA, y = OS_Score)) +
  #stat_bin_hex(bins=16, col="white") + 
  geom_count(alpha=0.5) +
  geom_smooth(method = "lm", formula = y ~ x, col="black", fullrange= T) +
  theme_linedraw()

sp6 <- ggplot(behav1, aes(x = AvoidB, y = OS_Score)) +
  #stat_bin_hex(bins=16, col="white") +
  geom_count(alpha=0.5) +
  geom_smooth(method = "lm", formula = y ~ x, col="red", fullrange= T) +
  theme_linedraw()

grid.arrange(sp1, sp2, sp3, sp4, sp5, sp6, nrow = 3)
```

## Experiment 2

First, we are going to load the results from Experiment 2 in "wide" summary format.

```{r}
behav2 <- read.table("experiment2.txt", header=T, sep="\t")
```

We are then going to remove all of the participants for whom we do not have RAPM or PSS data: 

```{r}
behav2 <- subset(behav2,
                 !is.na(behav2$BARAPM) &
                   !is.na(behav2$AvoidB))
```


Finally, for consistency, we are going to create a new variable `RAPM_Accuracy` represents the proportion of correct responses.

```{r}
behav2$RAPM_Accuracy <- behav2$BARAPM / 12
```

Because the first two problems are incredibly simple, we are going to exclude participants who did not solve at least 2 problems.

```{r}
behav2 <- subset(behav2, behav2$BARAPM > 2 )
```

In this experiment, we do not have sufficient data from AOSPAN, so we are going to focus only on three variables of interest:

```{r}
vars_of_interest <- c("ChooseA", "AvoidB", "RAPM_Accuracy") # No OS Score
```

### Descriptive statistics

As before, let's first look at their distribution:

```{r}
longb2 <- gather(behav2, variable, measure, vars_of_interest)
ggplot(longb2, aes(measure, fill=variable)) +
  geom_histogram(col=I("white"), bins = 16) +
  facet_wrap( . ~ variable, nrow = 2, scales= "free") +
  theme_linedraw()
```

Like before, let's look at their mean values:

```{r}
ggplot(longb2, aes(x=variable, y=measure, fill=variable)) +
  stat_summary(fun.data="mean_se", geom = "bar", width=0.5) +
  stat_summary(fun.data="mean_se", geom = "errorbar", width=0.1) +
  facet_wrap( . ~ variable, nrow = 2) +
  theme_linedraw()
```


### A comparison of Choose and Avoid accuracies

As expected, the mean values of Choose (_M_ = `r round(mean(behav2$ChooseA), 3)`, _SD_ = `r round(sd(behav2$ChooseA), 3)`) and Avoid (_M_ = `r round(mean(behav2$AvoidB), 3)`, _SD_ = `r round(sd(behav2$AvoidB), 3)`) are approximately the same. A _t_-test shows no difference between the two values:

```{r}
t <- t.test(behav2$ChooseA, behav2$AvoidB, paired = T)
```

with _t_(`r t$parameter`) = `r t$statistic`, _p_ = `r t$p.value`.

### Correlations between variables

First, we can examine the correlation matrix between these varibles:

```{r}
cor(behav2[vars_of_interest]) %>%
  kable(digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We can also calculate the correspinding _p_-values:

```{r}
behav2[vars_of_interest] %>% 
  as.matrix() %>% 
  rcorr() -> pvals

pvals$P %>%
  kable(digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

And finally, we can examine the scatterplots of the correlations between variables:

```{r warning=F}
sp1 <- ggplot(behav2, aes(x = ChooseA, y = AvoidB)) +
  #stat_bin_hex(bins=16, col="white") + 
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col="black", fullrange= T) +
  xlab("Choose Accuracy") +
  ylab("Avoid Accuracy") + 
  theme_linedraw()

sp2 <- ggplot(behav2, aes(x = ChooseA, y = RAPM_Accuracy)) +
  #stat_bin_hex(bins = 12, col="white") + 
  geom_count(alpha =0.5) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col="black", fullrange= T) +
  theme_linedraw()

sp3 <- ggplot(behav2, aes(x = AvoidB, y = RAPM_Accuracy)) +
  #stat_bin_hex(bins = 12, col="white") + 
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col="red", fullrange= T) +
  theme_linedraw()

grid.arrange(sp1, sp2, sp3, nrow = 2)
```

## Experiment 3

Experiment 3 was conducted in the fMRI scanner. In addition to the behavioral data, we have fMRI data from a set of ROIs.

First, let's load the Experiment 3 data in ``long'' format:

```{r}
exp3l <- read.table("experiment3/BAR_behavioral_data_16.txt", header=T) 
```

We need to filter out the ``Special`` problems, which were performed last and were not part of the task:

```{r}
exp3l %>% filter(Rules != "Special") -> exp3l
```

Now, a potential problem in this experiment is that participants might time out, so we need to count how many times that happened. Timed-out responses are marked as having a duration of 30,000 ms and 4,000 ms for the Problem and Choice phases, respectively.


The stats show that, out of `r length(exp3l$Problem)` trials, only `r length(exp3l$Problem[exp3l$Problem == 30000])` timed-out at the Problem phase (`r round(100 * length(exp3l$Problem[exp3l$Problem == 30000])/length(exp3l$Problem), 2)`%) 
and  `r length(exp3l$Choice[exp3l$Choice == 4000])` timed-out at the Choice phase (`r round(100 * length(exp3l$Choice[exp3l$Choice == 4000])/length(exp3l$Choice), 2)`%)

### Descriptive statistics

To conduct further analysis, we need to aggregate the data:

```{r}
group_by(exp3l, Subject) %>%
  summarise(Problem=mean(Problem),
            Choice=mean(Choice),
            Accuracy=mean(Accuracy)) ->
  exp3w
```

In this case, the variables of interest are `Problem` response time, `Choice` response time, and problem `Accuracy`.

```{r}
vars_of_interest <- c("Problem", "Choice", "Accuracy") # No OS Score
```

As before, we can look at their distribution:

```{r}
longb3 <- gather(exp3w, variable, measure, vars_of_interest)
ggplot(longb3, aes(measure, fill=variable)) +
  geom_histogram(col=I("white"), bins = 16) +
  facet_wrap( . ~ variable, nrow = 2, scales= "free") +
  theme_linedraw()
```

and their mean values:

```{r}
ggplot(longb3, aes(x=variable, y=measure, fill=variable)) +
  stat_summary(fun.data="mean_se", geom = "bar", width=0.5) +
  stat_summary(fun.data="mean_se", geom = "errorbar", width=0.1) +
  geom_rug() +
  facet_wrap( . ~ variable, nrow = 2, scales = "free") +
  theme_linedraw()
```

### Correlations between variables

First, we can examine the correlation matrix between these varibles:

```{r}
cor(exp3w[vars_of_interest]) %>%
  kable(digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We can also calculate the correspinding _p_-values:

```{r}
exp3w[vars_of_interest] %>% 
  as.matrix() %>% 
  rcorr() -> pvals

pvals$P %>%
  kable(digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
```

And finally, we can examine the scatterplots of the correlations between variables:

```{r warning=F}
sp1 <- ggplot(exp3w, aes(x = Choice, y = Accuracy)) +
  #stat_bin_hex(bins=16, col="white") + 
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col="black", fullrange= T) +
  geom_rug() +
  theme_linedraw()

sp2 <- ggplot(exp3w, aes(x = Choice, y = Problem)) +
  #stat_bin_hex(bins = 12, col="white") + 
  geom_count(alpha =0.5) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col="black", fullrange= T) +
  geom_rug() +
  theme_linedraw()

sp3 <- ggplot(exp3w, aes(x = Problem, y = Accuracy)) +
  #stat_bin_hex(bins = 12, col="white") + 
  geom_count(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, 
              col="red", fullrange= T) +
  geom_rug() +
  theme_linedraw()

grid.arrange(sp1, sp2, sp3, nrow = 2)
```